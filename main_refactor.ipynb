{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KDM project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "T34lv-eU3Qge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sympy.logic.boolalg import to_cnf\n",
        "from sympy.abc import A, B, C, D, E, F, G, H, J\n",
        "import itertools\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "8GnD2xG-Yogn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install python-sat"
      ],
      "metadata": {
        "id": "qmIq0duBhPyO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pysat.examples.fm import FM\n",
        "from pysat.formula import WCNF\n",
        "from itertools import combinations\n",
        "import math"
      ],
      "metadata": {
        "id": "PsyheJ3iyYwZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "    def __init__(self, n_neurons):\n",
        "        self.n_neurons = n_neurons\n",
        "        self.wcnf_form = WCNF()\n",
        "        self.FuMalik = None\n",
        "\n",
        "        self.weights_solution = None\n",
        "\n",
        "    def compute_solution(self):\n",
        "        self.FuMalik = FM(self.wcnf_form, verbose = 1)\n",
        "        self.FuMalik.compute()\n",
        "\n",
        "        self.weights_solution = self.FuMalik.model[:self.n_neurons]\n",
        "        self.weights_solution = [val > 0 for val in self.weights_solution]  # Bool vector\n",
        "\n",
        "    def append_positive_clause(self, data, target_index):\n",
        "        # print(f'Encoding for y True')\n",
        "        for positive_clause in data.positive_clauses:\n",
        "            # if (1, -2) clause --> [(w[0] V ~x[i][0]) V (~w[1] V x[i][1])] clause\n",
        "            clause_to_add = []\n",
        "            for index in positive_clause:\n",
        "                abs_index = abs(index)\n",
        "                prop_weight = data.prop_weights[abs_index - 1]  # variable, where weight is encoded\n",
        "                prop_feature = data.prop_features[target_index][abs_index - 1]  # feature, that is encoded\n",
        "\n",
        "                if index < 0:\n",
        "                    clause_to_add.extend([int(-prop_weight), int(prop_feature)])\n",
        "                else:\n",
        "                    clause_to_add.extend([int(prop_weight), int(-prop_feature)])\n",
        "            # print(f'Clause: {clause_to_add}')\n",
        "            self.wcnf_form.append(clause_to_add, weight = 1)\n",
        "\n",
        "    def calc_update(self, letters, x, w):\n",
        "        # ['~', 'x', '2']\n",
        "        x_or_w = ''\n",
        "        to_put_minus = 1\n",
        "\n",
        "        if letters[0] == '~':\n",
        "            x_or_w = letters[1]\n",
        "            to_put_minus = -1\n",
        "        else:\n",
        "            x_or_w = letters[0]\n",
        "            to_put_minus = 1\n",
        "        \n",
        "        index = int(letters[-1])\n",
        "        if x_or_w == 'x':\n",
        "            return int(to_put_minus * x[index - 1])\n",
        "            \n",
        "        if x_or_w == 'w':\n",
        "            return int(to_put_minus * w[index - 1])\n",
        "\n",
        "    def append_negative_clause(self, data, target_index):\n",
        "        # print(f'Encoding for negative y')\n",
        "        for negative_clause in data.negative_clauses:\n",
        "            # ('w 1', 'x 1', '~ w 2', '~ x 2')\n",
        "\n",
        "            clause_to_add = []\n",
        "            for symbol in negative_clause:\n",
        "                # symbol is a string, like \"w 1\" or \"~ x 2\"\n",
        "                letters = symbol.split(' ')\n",
        "                clause_to_add.append(int(self.calc_update(letters, data.prop_features[target_index], data.prop_weights)))\n",
        "            \n",
        "            # print(f'Clause: {clause_to_add}')\n",
        "            self.wcnf_form.append(clause_to_add, weight = 1)\n",
        "\n",
        "\n",
        "    def encode_soft_clauses(self, data):\n",
        "        Y_train = data.Y_train\n",
        "\n",
        "        for i in range(len(Y_train)):\n",
        "    \n",
        "            y_i = Y_train[i]\n",
        "\n",
        "            if y_i == True:\n",
        "                self.append_positive_clause(data, target_index = i)\n",
        "\n",
        "            if y_i == False:\n",
        "                self.append_negative_clause(data, target_index = i)\n",
        "            \n",
        "    def encode_hard_clauses(self, data):\n",
        "        for i in range(len(data.X_train)):\n",
        "            for j in range(len(data.X_train[0])):\n",
        "                \n",
        "                if data.X_train[i][j] == True:\n",
        "                    self.wcnf_form.append([int(data.prop_features[i][j])])\n",
        "                else:\n",
        "                    self.wcnf_form.append([int(-data.prop_features[i][j])])\n",
        "\n",
        "    def calc_accuracy(self, X, Y):\n",
        "        int_weights = np.array(self.weights_solution, dtype = 'int')\n",
        "\n",
        "        pred = np.sign(np.dot(X, int_weights))\n",
        "        return accuracy_score(Y, pred)\n",
        "\n",
        "    def calc_metrics(self, X, Y):\n",
        "\n",
        "        acc = self.calc_accuracy(\n",
        "            np.array(X, dtype = 'int'),\n",
        "            np.array(Y, dtype = 'int')\n",
        "        )\n",
        "        # print(f'Accuracy: {acc}')\n",
        "        return acc\n",
        "        \n",
        "class DataProperties:\n",
        "    def __init__(self, n_features, n_samples, train_percentage):\n",
        "        self.n_features = n_features\n",
        "        self.n_samples = n_samples\n",
        "        self.train_percentage = train_percentage\n",
        "        self.test_percentage = 1 - train_percentage\n",
        "        \n",
        "        self.n_train = int(self.train_percentage * self.n_samples)\n",
        "        self.n_test = self.n_samples - self.n_train\n",
        "\n",
        "        self.X_train = None\n",
        "        self.Y_train = None\n",
        "        self.X_test = None\n",
        "        self.Y_test = None\n",
        "        \n",
        "        self.prop_features = None\n",
        "        self.prop_weights = np.array([i + 1 for i in range(n_features)])\n",
        "\n",
        "        self.features_combinations = None\n",
        "        self.cartesian_products = None\n",
        "\n",
        "        self.positive_clauses = []\n",
        "        self.negative_clauses = []\n",
        "    \n",
        "    def encode_propositional_features(self):\n",
        "        self.prop_features = np.array(\n",
        "            [[i*self.n_features + j + max(self.prop_weights) + 1 for j in range(self.n_features)] for i in range(self.n_train)]\n",
        "        )\n",
        "\n",
        "    def prepare_dataset(self, func):\n",
        "        np.random.seed(123)\n",
        "\n",
        "        sample_arr = [True, False]\n",
        "        \n",
        "\n",
        "        self.X_train = np.random.choice(sample_arr, size = (self.n_train, self.n_features))\n",
        "        self.X_test = np.random.choice(sample_arr, size = (self.n_test, self.n_features))\n",
        "\n",
        "        self.Y_train = [func(x) for x in self.X_train]\n",
        "        self.Y_test = [func(x) for x in self.X_test]\n",
        "\n",
        "    def prepare_balanced_dataset(self, func):\n",
        "        # np.random.seed(123) \n",
        "        \n",
        "        X = list(itertools.product([False, True], repeat=self.n_features))\n",
        "        Y = np.array([func(x) for x in X])\n",
        "\n",
        "        idx_true = np.where(Y == True)[0]\n",
        "        idx_false = np.where(Y == False)[0]\n",
        "        assert(len(idx_true) + len(idx_false) == len(Y))\n",
        "\n",
        "        # We need to balance dataset --> we will use the subsets\n",
        "        # of True and False of equal cardinality (minimal of the\n",
        "        # True or False subsets)\n",
        "        min_length = min(len(idx_true), len(idx_false))\n",
        "\n",
        "        y_balanced = []\n",
        "        x_balanced = []\n",
        "\n",
        "        for i in range(min_length):\n",
        "            true_idx = idx_true[i]\n",
        "            false_idx = idx_false[i]\n",
        "            \n",
        "            y_balanced.append(Y[true_idx])\n",
        "            x_balanced.append(X[true_idx])\n",
        "            \n",
        "            y_balanced.append(Y[false_idx])\n",
        "            x_balanced.append(X[false_idx])\n",
        "\n",
        "        self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(\n",
        "            x_balanced, \n",
        "            y_balanced, \n",
        "            stratify = y_balanced,\n",
        "            test_size = self.n_test / self.n_train,\n",
        "            random_state = 42\n",
        "        )\n",
        "\n",
        "        common_data = set(self.X_train).intersection(set(self.X_test))\n",
        "        assert(len(common_data) == 0)  # No common data\n",
        "\n",
        "    def encode_features_combinations(self):\n",
        "\n",
        "        majority_size = int(np.ceil(self.n_features / 2))\n",
        "        assert(majority_size == np.floor(self.n_features / 2) + 1)\n",
        "        self.features_combinations = list(combinations(self.prop_weights, majority_size))\n",
        "\n",
        "    def remove_redundant(self, elements):\n",
        "        res = []\n",
        "        for e in elements:\n",
        "            if not (e in res):\n",
        "                res.append(e)\n",
        "        return res\n",
        "\n",
        "    def encode_cartesian_products(self):\n",
        "        prods = list(itertools.product(*self.features_combinations))\n",
        "        prods = [np.unique(combo).tolist() for combo in prods]\n",
        "        self.cartesian_products = self.remove_redundant(prods)\n",
        "\n",
        "    def prepare_predfinal_clauses(self):\n",
        "        predfinal_clauses = []\n",
        "        for product in self.cartesian_products:\n",
        "            bracket = []\n",
        "            for val in product:\n",
        "                bracket.append([val, -val])\n",
        "            predfinal_clauses.append(bracket)\n",
        "        return predfinal_clauses\n",
        "\n",
        "\n",
        "    def encode_positive_clauses(self):\n",
        "        # Each element of optimized_products represents:\n",
        "        # [1, 2] --> (w1 == x_i1) V (w2 == x_i2). But we have not transfered to CNF yet\n",
        "        # To do that: [(~w1 V x_i1) & (w1 V ~x_i1)] V [(~w2 V x_i2) & (w2 V ~x_i2)]\n",
        "        # which is 'encoded' as [[1, -1], [2, -2]]\n",
        "\n",
        "        predfinal_clauses = self.prepare_predfinal_clauses()\n",
        "\n",
        "        # And now we are creating final clauses\n",
        "        for predfinal_clause in predfinal_clauses:\n",
        "            clauses = list(itertools.product(*predfinal_clause))\n",
        "            \n",
        "            for clause in clauses:\n",
        "                self.positive_clauses.append(clause)\n",
        "\n",
        "    def encode_negative_clauses(self):\n",
        "\n",
        "        ws_xs_list = []\n",
        "        for combo in self.features_combinations:\n",
        "            # print(combo)\n",
        "            symbols = []\n",
        "            for i in combo:\n",
        "                symbols.extend([[f'w {i}', f'~ w {i}']])\n",
        "                symbols.extend([[f'x {i}', f'~ x {i}']])\n",
        "            ws_xs_list.append(symbols)\n",
        "        \n",
        "        for combination in ws_xs_list:\n",
        "            for clause in itertools.product(*combination):\n",
        "                # print(clause)\n",
        "                self.negative_clauses.append(clause)\n"
      ],
      "metadata": {
        "id": "myBBKiZMCTl_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic pipeline"
      ],
      "metadata": {
        "id": "QRGzAw8gfY5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data, encode propositional features, compute solution"
      ],
      "metadata": {
        "id": "T9Csoc-05KxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(n_neurons = 5)\n",
        "\n",
        "data = DataProperties(\n",
        "    n_features = model.n_neurons,\n",
        "    n_samples = 2 ** model.n_neurons,\n",
        "    train_percentage = 0.8  # test % = 100 - train %\n",
        ")\n",
        "\n",
        "\n",
        "# define propositional variables for X\n",
        "# propositional features cannot have same indices as w --> + 1 + max(w)\n",
        "data.encode_propositional_features()\n",
        "\n",
        "# Now prepare all cartesian products (for the case whey y == 1)\n",
        "data.encode_features_combinations()\n",
        "data.encode_cartesian_products()\n",
        "\n",
        "data.encode_positive_clauses()\n",
        "data.encode_negative_clauses()\n",
        "\n",
        "# Prepare data\n",
        "def check_2nd_feature(x):\n",
        "    return x[1] == True # and x[0] == False\n",
        "\n",
        "data.prepare_balanced_dataset(func = check_2nd_feature)\n",
        "\n",
        "# Distribution of dataset:\n",
        "print(f'Distribution of Negative and positive classes in data:')\n",
        "fig, ax = plt.subplots(2, 1)\n",
        "sns.histplot(np.array(data.Y_train, dtype = 'int'), ax = ax[0])\n",
        "sns.histplot(np.array(data.Y_test, dtype = 'int'), ax = ax[1])\n",
        "\n",
        "\n",
        "model.encode_soft_clauses(data)\n",
        "model.encode_hard_clauses(data)\n",
        "model.compute_solution()\n",
        "\n",
        "train_acc = model.calc_metrics(data.X_train, data.Y_train)\n",
        "test_acc = model.calc_metrics(data.X_test, data.Y_test)\n",
        "\n",
        "print(f'Train acc: {train_acc}, Test acc: {test_acc}')"
      ],
      "metadata": {
        "id": "1nnnBigL5NHG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "a638604a-63fd-4705-a755-ff8868f8527d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution of Negative and positive classes in data:\n",
            "Train acc: 0.782608695652174, Test acc: 0.6666666666666666\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical experiments"
      ],
      "metadata": {
        "id": "TmHsh6MSNov_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy versus number of neurons"
      ],
      "metadata": {
        "id": "ECnIdMp8Nuip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(\n",
        "    target_func,\n",
        "    data_size,\n",
        "    train_percentage,\n",
        "    n_neurons,\n",
        "    do_computations\n",
        "):\n",
        "    model = Model(n_neurons = n_neurons)\n",
        "\n",
        "    data = DataProperties(\n",
        "        n_features = model.n_neurons,\n",
        "        n_samples = data_size,\n",
        "        train_percentage = train_percentage\n",
        "    )\n",
        "\n",
        "    data.encode_propositional_features()\n",
        "    data.encode_features_combinations()\n",
        "    data.encode_cartesian_products()\n",
        "    data.encode_positive_clauses()\n",
        "    data.encode_negative_clauses()\n",
        "    print(f'A')\n",
        "    data.prepare_balanced_dataset(func = target_func)\n",
        "    print(f'A')\n",
        "    \n",
        "\n",
        "    # Distribution of dataset:\n",
        "    train_arr = np.array(data.Y_train, dtype = 'int')\n",
        "    test_arr = np.array(data.Y_test, dtype = 'int')\n",
        "    print(f'{len(train_arr[train_arr == 1])} train 1')\n",
        "    print(f'{len(train_arr[train_arr == 0])} train 0')\n",
        "    print(f'{len(test_arr[test_arr == 1])} test 1')\n",
        "    print(f'{len(test_arr[test_arr == 0])} test 0')\n",
        "\n",
        "    model.encode_soft_clauses(data)\n",
        "    model.encode_hard_clauses(data)\n",
        "\n",
        "    \n",
        "    cpu_start = default_timer()\n",
        "    if do_computations:\n",
        "        model.compute_solution()\n",
        "    cpu_end = default_timer()\n",
        "\n",
        "    if do_computations:\n",
        "        train_acc = model.calc_metrics(data.X_train, data.Y_train)\n",
        "        test_acc = model.calc_metrics(data.X_test, data.Y_test)\n",
        "    else:\n",
        "        train_acc = 0\n",
        "        test_acc = 0\n",
        "\n",
        "    # print(f'Train acc: {train_acc}, Test acc: {test_acc}')\n",
        "    return dict(\n",
        "        train_acc = train_acc,\n",
        "        test_acc = test_acc,\n",
        "        cpu_time = cpu_end - cpu_start, # seconds\n",
        "        n_neurons = n_neurons,\n",
        "        n_soft_clauses = len(model.wcnf_form.soft),\n",
        "        n_hard_clauses = len(model.wcnf_form.hard),\n",
        "        Y_train = data.Y_train,\n",
        "        Y_test = data.Y_test\n",
        "    )"
      ],
      "metadata": {
        "id": "9ZZAezG7OA7_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Number of clauses VS number of neurons"
      ],
      "metadata": {
        "id": "guwaruKHXhjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we fix all parameters, except for the number of neurons, to check how number of soft and hard clauses increases with number of neurons"
      ],
      "metadata": {
        "id": "FWvdVPqqYBZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_hard_clauses = []\n",
        "n_soft_clauses = []\n",
        "\n",
        "n_neurons = [3, 5]# [1, 3, 5, 7, 9]\n",
        "\n",
        "def true_func(x):\n",
        "    return True\n",
        "\n",
        "target_func = true_func\n",
        "data_size = 50\n",
        "train_percentage = 0.7\n",
        "do_computations = False\n",
        "\n",
        "# experiment_parameters = dict(\n",
        "    \n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "for n in n_neurons:\n",
        "    res = run_experiment(\n",
        "        n_neurons = n,\n",
        "        target_func = true_func,\n",
        "        data_size = data_size,\n",
        "        train_percentage = train_percentage,\n",
        "        do_computations = False\n",
        "        # **experiment_parameters\n",
        "        # target_func = true_func,\n",
        "    )\n",
        "    n_hard_clauses.append(\n",
        "        res['n_hard_clauses']\n",
        "    )\n",
        "    n_soft_clauses.append(\n",
        "        res['n_soft_clauses']\n",
        "    )\n"
      ],
      "metadata": {
        "id": "xVTV7LLbXkjk",
        "outputId": "04e0f861-fca3-40f9-bc53-56924d6819ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-54e133a9be59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mdata_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtrain_percentage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_percentage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mdo_computations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# **experiment_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# target_func = true_func,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-621f74f43b61>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(target_func, data_size, train_percentage, n_neurons, do_computations)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_negative_clauses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_balanced_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-3cea52c8c2a7>\u001b[0m in \u001b[0;36mprepare_balanced_dataset\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_balanced\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_test\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         )\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     n_train, n_test = _validate_shuffle_split(\n\u001b[0;32m-> 2421\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2422\u001b[0m     )\n\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2099\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m             \u001b[0;34m\"aforementioned parameters.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2102\u001b[0m         )\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.42857142857142855 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CPU time VS number of neurons"
      ],
      "metadata": {
        "id": "KaRNqiwLNyi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_1st_feature(x):\n",
        "    return x[0] == True\n",
        "\n",
        "network_sizes = [3, 5, 7]\n",
        "target_func = check_1st_feature\n",
        "data_size = 60\n",
        "train_percentage = 0.8\n",
        "\n",
        "def do_test(network_sizes, target_func, data_size, train_percentage):\n",
        "    res = {}\n",
        "    for n_neurons in network_sizes:\n",
        "        res[n_neurons] = run_experiment(\n",
        "            target_func = target_func, \n",
        "            data_size = data_size, \n",
        "            train_percentage = train_percentage, \n",
        "            n_neurons = n_neurons\n",
        "        )\n",
        "    return res\n",
        "\n",
        "\n",
        "experiment_res = do_test(network_sizes, target_func, data_size, train_percentage)"
      ],
      "metadata": {
        "id": "befLQrepR1qB",
        "outputId": "efcdf6d8-b264-450c-9b07-2128bd4b6ea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24 train 1\n",
            "24 train 0\n",
            "5 test 1\n",
            "7 test 0\n",
            "22 train 1\n",
            "26 train 0\n",
            "6 test 1\n",
            "6 test 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_res"
      ],
      "metadata": {
        "id": "QZEr8_8aTLzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison with 1-layer FFNN"
      ],
      "metadata": {
        "id": "H92Uj5M2N2LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8d-hukvFNrBv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}